{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hands-on Exercise 02 \n",
    "# Text Classification using NaiveBayesClassifier using NLTK\n",
    "\n",
    "Source: https://www.nltk.org/book/ch06.html\n",
    "\n",
    "adapted by Raghava Mukkamala \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "import textwrap \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Fredi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capsule', ':', 'the', 'best', 'place', 'to', 'start', ...]\n"
     ]
    },
    {
     "data": {
      "text/plain": "['neg', 'pos']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "\n",
    "# if you get error then you can download movie reviews by using \n",
    "# nltk.download('movie_reviews') and then unpack the downloaded zip file.\n",
    "\n",
    "print(movie_reviews.words('pos/cv957_8737.txt'))\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Transforming movie review documents\n",
    "\n",
    "    Load the documents from ../nltk_data/corpora/movie_reviews and\n",
    "    transform them in the following format.\n",
    "\n",
    "    [\n",
    "    ([ 'gotten', 'a', 'four', 'star', 'rating', 'out', 'of', 'me', '.'], 'pos'), \n",
    "    ([ 'free', 'tickets',  'definitely', 'worth', 'checking', 'out', '.'], 'pos')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_reviews.categories():  ['neg', 'pos']\n",
      "number of documents:  2000\n",
      "+----------------------------------------------------------------------------------+----------+\n",
      "|                                Document Features                                 | Category |\n",
      "+----------------------------------------------------------------------------------+----------+\n",
      "| for,better,or,worse,,,the,appearance,of,basic,instinct,in,the,movie,marketplace, |   neg    |\n",
      "| gave,the,greenlight,to,a,whole,slew,of,overheated,,,oversexed,,,underwritten,thr |          |\n",
      "| illers,.,apparently,not,having,joe,eszterhas,as,the,writer,doesn,',t,change,a,th |          |\n",
      "|                       ing,,,since,body,of,evidence,wasn,'                        |          |\n",
      "|                                                                                  |          |\n",
      "|                                                                                  |          |\n",
      "| *,*,the,following,review,contains,spoilers,*,*,\",please,someone,stop,joel,schuma |   neg    |\n",
      "| cher,before,he,vomits,into,a,film,canister,again,and,tries,to,pass,it,off,as,a,m |          |\n",
      "| ovie,.,\",--,chuck,dowling,,,the,jacksonville,film,journal,i,wrote,the,above,sent |          |\n",
      "|                                ence,in,my,review                                 |          |\n",
      "|                                                                                  |          |\n",
      "|                                                                                  |          |\n",
      "| carry,on,at,your,convenience,is,all,about,the,goings,-,on,in,the,factory,of,a,to |   neg    |\n",
      "| ilet,manufacturer,,,wc,boggs,(,kenneth,williams,),.,once,they,have,won,an,order, |          |\n",
      "| to,manufacture,1000,bidets,in,two,months,and,charles,coote,(,charles,hawtrey,),h |          |\n",
      "|                                  as,designed,a                                   |          |\n",
      "|                                                                                  |          |\n",
      "|                                                                                  |          |\n",
      "| when,you,',ve,run,out,of,old,tv,shows,to,turn,into,movies,,,i,guess,you,try,vide |   neg    |\n",
      "| o,games,.,why,did,i,go,to,see,mortal,kombat,:,annihilation,?,the,quest,to,seek,a |          |\n",
      "|           n,answer,to,this,query,may,prove,a,better,movie,that,the,one           |          |\n",
      "|                                                                                  |          |\n",
      "|                                                                                  |          |\n",
      "| it,',s,hard,not,to,recommend,\",the,others,.,\",the,supernatural,thriller,,,writte |   pos    |\n",
      "| n,and,directed,by,alejandro,amen,?,bar,(,\",open,your,eyes,\",),,,adroitly,establi |          |\n",
      "| shes,and,maintains,a,low,-,key,atmosphere,of,menace,.,the,cinematography,,,by,ja |          |\n",
      "|                                vier,aguirresarobe                                |          |\n",
      "|                                                                                  |          |\n",
      "|                                                                                  |          |\n",
      "+----------------------------------------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "print ('movie_reviews.categories(): ', movie_reviews.categories())\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('number of documents: ', len(documents))\n",
    "\n",
    "tab = PrettyTable(['Document Features', 'Category'])\n",
    "\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents[0:5]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=80)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "#     print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Frequency distribution of words \n",
    "\n",
    "    Load all words from all the documents from the movie reviews to use \n",
    "    most common words as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from movie review corpus:  1583820\n",
      "most freq words:  [('off', 1581), ('too', 1577), ('any', 1574), ('does', 1568), ('really', 1558), ('had', 1546), ('while', 1539), ('films', 1536), ('how', 1517), ('plot', 1513)]\n",
      "word_features[:25]:  [',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-', ')', '(', 'as', 'with', 'for', 'his', 'this', 'film', 'i', 'he']\n"
     ]
    }
   ],
   "source": [
    "print('total words from movie review corpus: ', len(movie_reviews.words()))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "\n",
    "most_freq_words = all_words.most_common(2000)\n",
    "\n",
    "print('most freq words: ', most_freq_words[100:110])\n",
    "\n",
    "word_features = [word for (word, count) in most_freq_words]\n",
    "\n",
    "print('word_features[:25]: ', word_features[:25])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting documents into training set containing features\n",
    "\n",
    "    Extarcting features from a document and transforming them feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(,)': True, 'contains(the)': True, 'contains(.)': True, 'contains(a)': True, 'contains(and)': True, 'contains(of)': True, 'contains(to)': True, \"contains(')\": True, 'contains(is)': True, 'contains(in)': True, 'contains(s)': True, 'contains(\")': True, 'contains(it)': True, 'contains(that)': True, 'contains(-)': True, 'contains())': True, 'contains(()': True, 'contains(as)': True, 'contains(with)': True, 'contains(for)': True, 'contains(his)': True, 'contains(this)': True, 'contains(film)': False, 'contains(i)': False, 'contains(he)': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features(document):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        \n",
    "    \"\"\"\n",
    "    document_words = set(document)\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "\n",
    "words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "\n",
    "feat_dict = get_document_features(words_doc)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n",
    "# print(documents[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training set and training Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "test "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.85\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     13.3 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      7.6 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.5 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.8 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.8 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.6 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.5 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.2 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.1 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      5.0 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.0 : 1.0\n",
      "         contains(waste) = True              neg : pos    =      4.9 : 1.0\n",
      "         contains(worst) = True              neg : pos    =      4.5 : 1.0\n",
      "         contains(bland) = True              neg : pos    =      4.5 : 1.0\n",
      "           contains(era) = True              pos : neg    =      4.4 : 1.0\n",
      "      contains(terrific) = True              pos : neg    =      4.1 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =      4.0 : 1.0\n",
      "       contains(unfunny) = True              neg : pos    =      4.0 : 1.0\n",
      "     contains(pointless) = True              neg : pos    =      3.9 : 1.0\n",
      "     contains(fantastic) = True              pos : neg    =      3.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "featuresets = [(get_document_features(d), c) for (d,c) in documents]\n",
    "\n",
    "print(len(featuresets))\n",
    "\n",
    "\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "print(\"test\", train_set)\n",
    "print(\"type\", type(train_set))\n",
    "\n",
    "print(len(test_set))\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "\n",
    "print('accuracy: ', nltk.classify.accuracy(classifier, test_set)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outstanding : neg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_review = 'outstanding'\n",
    "\n",
    "sample_review_doc_feats = get_document_features(sample_review.split())\n",
    "\n",
    "# print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print(sample_review, ':' , classifier.classify(sample_review_doc_feats))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Handson Exercise - 02:</font>\n",
    "\n",
    "    Use Reuters Corpus from nltk and build a Naive Bayes classifier for the categories of Reuters Corpus.\n",
    "    Please refer to https://www.nltk.org/book/ch02.html for an example on how to access Reuters Corpus. \n",
    "    Use some test documents to test the accuracy of the classifier.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10788\n",
      "printing the categories for first 10 docs!\n",
      "+------------+----------------------------------------+\n",
      "|   fileid   |                Category                |\n",
      "+------------+----------------------------------------+\n",
      "| test/14826 |                 trade                  |\n",
      "| test/14828 |                 grain                  |\n",
      "| test/14829 |             crude,nat-gas              |\n",
      "| test/14832 | corn,grain,rice,rubber,sugar,tin,trade |\n",
      "| test/14833 |            palm-oil,veg-oil            |\n",
      "| test/14839 |                  ship                  |\n",
      "| test/14840 | coffee,lumber,palm-oil,rubber,veg-oil  |\n",
      "| test/14841 |              grain,wheat               |\n",
      "| test/14842 |                  gold                  |\n",
      "| test/14843 |                  acq                   |\n",
      "+------------+----------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make sure that NLTK and reuters corpus is accessible\n",
    "import nltk\n",
    "\n",
    "# If you get an error saying that 'Resource reuters not found.' , \n",
    "# you can download using the following code.\n",
    "\n",
    "#nltk.download('reuters')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Check how many fileids in the reuters corpus to see that we have access.\n",
    "print(len(reuters.fileids()))\n",
    "\n",
    "\n",
    "tab = PrettyTable(['fileid', 'Category'])\n",
    "\n",
    "index = 0\n",
    "\n",
    "print('printing the categories for first 10 docs!')\n",
    "\n",
    "for id in reuters.fileids():\n",
    "    index += 1\n",
    "    cats = textwrap.fill(','.join(reuters.categories(id)), width=40)\n",
    "    tab.add_row([id, cats])\n",
    "    if index == 10:\n",
    "        break\n",
    "    \n",
    "print(tab)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test/15618',\n",
       " 'test/15649',\n",
       " 'test/15676',\n",
       " 'test/15728',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15952',\n",
       " 'test/17767',\n",
       " 'test/17769',\n",
       " 'test/18024',\n",
       " 'test/18263',\n",
       " 'test/18908',\n",
       " 'test/19275',\n",
       " 'test/19668',\n",
       " 'training/10175',\n",
       " 'training/1067',\n",
       " 'training/11208',\n",
       " 'training/11316',\n",
       " 'training/11885',\n",
       " 'training/12428',\n",
       " 'training/13099',\n",
       " 'training/13744',\n",
       " 'training/13795',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1652',\n",
       " 'training/1970',\n",
       " 'training/2044',\n",
       " 'training/2171',\n",
       " 'training/2172',\n",
       " 'training/2191',\n",
       " 'training/2217',\n",
       " 'training/2232',\n",
       " 'training/3132',\n",
       " 'training/3324',\n",
       " 'training/395',\n",
       " 'training/4280',\n",
       " 'training/4296',\n",
       " 'training/5',\n",
       " 'training/501',\n",
       " 'training/5467',\n",
       " 'training/5610',\n",
       " 'training/5640',\n",
       " 'training/6626',\n",
       " 'training/7205',\n",
       " 'training/7579',\n",
       " 'training/8213',\n",
       " 'training/8257',\n",
       " 'training/8759',\n",
       " 'training/9865',\n",
       " 'training/9958']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reuters.words(categories=['barley', 'corn'])))\n",
    "\n",
    "reuters.fileids('barley')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters.fileids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}